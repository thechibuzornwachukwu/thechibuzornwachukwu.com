. . . and we are in BIG trouble

Press enter or click to view image in full size

Photo by Alexander Krivitskiy on Unsplash
Let’s be honest — if you’ve ever had a favorite sibling, friend, or co-worker (and you do), then you’ve been biased. Maybe it’s because of shared history, how they make you feel, or something as simple as “they just get me.”

That’s human.

But that same bias — left unchecked — is what breaks relationships, ruins systems, and silently rigs the game against people who don’t “fit the mold.” And here’s the kicker: AI is no different.

In fact, it learns from us. So if we’re biased (and we are), then you bet the tech we build is too.

Wait, AI Is Biased? Show Me.
Absolutely. Let’s talk real-life examples:

Uber reportedly set higher prices for iPhone users compared to Android users. Funny huh? Here’s proof.
A student performance predictor might decide that a student living in comfort is bound to succeed — even if their grades say otherwise.
A scholarship recommender might deny an underprivileged student just because the system read two damaged cars as “wealth.”
An AI-powered visa system might flag an Indian Nigerian applicant as a fraud risk because the internet overrepresents negative narratives about their country.
And how about this — some AIs trained on historical credit data assign higher risk scores to people of color. That’s not just bad data. That’s real-world harm.
These are not theoretical problems.

They’re happening right now.

And we have to deal with them — now.

The Ethics of AI: Not Just a “Tomorrow” Problem
Accenture’s Responsible AI team shared that only 35% of people trust AI systems. Can you blame them?

This stuff is complicated. But let me walk you through five big dilemmas we’re facing in the AI world — and why they matter.

1. The Privacy vs. Personalization Problem
We all want AI that “gets” us — but how much are we willing to give up for that? Your data? Your digital footprint? Your peace of mind?

Press enter or click to view image in full size

Photo by Sean Benesh on Unsplash
It’s a tightrope walk.

Regulations are steps in the right direction.

But with AI evolving faster than law, are we not playing catch up?

2. The Transparency vs. Complexity Dilemma
Ever heard of the “Black Box” problem? That’s when AI systems give you an answer, but you have no clue how they got there.

Transparency helps regulators, users, and developers stay on the same page, with systems we can trust.

Get Chibuzor Nwachukwu’s stories in your inbox
Join Medium for free to get updates from this writer.

Enter your email
Subscribe
In my musings on LinkedIn, I talk about call CAR-power — Company culture, Agility in market, and Relationships with users. When we embrace ethical transparency, we strengthen all three, such that even if your competitors copy your tech, they can’t copy your relationships, your agility, or your culture.

3. The Bias vs. Fairness Battle
“Good” and “bad” are subjective, but fairness in AI needs to be non-negotiable.

Bias shows up everywhere — even in places you wouldn’t expect, like medical imaging. One AI system was able to predict a patient’s race based purely on a chest scan. Let that sink in. How?

That’s the kind of unintended behavior that slips through when we don’t build with intentionality.

The stakes? Discrimination at scale.

Press enter or click to view image in full size

Photo by GR Stocks on Unsplash
4. The Autonomy vs. Control Trade-Off
The more powerful AI becomes, the less predictable it can be.

As we build systems that act more independently, we have to ask: who’s really in control? The user? The engineer? Or the code?

As Francesca Tabor once said:

The idea that increasing AI autonomy could reduce human autonomy isn’t far-fetched.” If we’re not careful, AI could stop being our tool — and start becoming our authority.

5. The Reliability vs. Safety Puzzle
We want AI that’s smart, fast, and adaptable. But we also want it to be safe, explainable, and ethical.

That balance isn’t easy.

I’ve been researching adversarial attacks on LLMs (think of it as “tricking” AI systems to behave badly), and trust me — there’s a reason why jailbreaking and prompt injection are hot topics. There’s a whole underground of misuse just waiting to be exploited.

The tech is powerful. But is it safe? The answer isn’t always yes.

So… Can We Fix This?
That’s the real question. And here’s the hard truth:

We can’t build ethical AI after the fact. We need to design it that way from the start.

And that means asking hard questions like:

Can bad AI be prevented — or just contained?
Is the real problem the tech, or the people training it?
What kind of future are we building, and for whom?
We talk about “Privacy by Design.” Well, it’s time we start demanding “Ethics by Design” too.

TL;DR: AI Reflects Us
If AI is biased, it’s because we are.

The challenge now is to build something better — something intentional. Because AI won’t fix itself. We have to choose to fix it.

Until next time, I leave you with this truth I live by:

“In God we trust and obey. For AI, we trust — but verify.”